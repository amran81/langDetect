{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dcb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import openpyxl\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36706c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model_path_fasttext = 'C:/Python311/fastText/lid.176.bin'\n",
    "model = fasttext.load_model(model_path_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8e7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Language Detection: 100%|█████████████████████████████████████████████████████| 164/164 [00:00<00:00, 354.77it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# Load the Excel file\n",
    "file_name = \"SubjectAppsDataset_exp03.xlsx\"\n",
    "df = pd.read_excel(file_name, sheet_name=\"baseline\")\n",
    "\n",
    "# Placeholder for language detection results\n",
    "detect_language_sentences = []\n",
    "count_language_sentences = []\n",
    "language_labels = []\n",
    "\n",
    "def classify_word(word, lang):\n",
    "    if (word.startswith('x') or\n",
    "        lang != 'en' or\n",
    "        re.search(r'([aiou])\\1{1,}$', word) or\n",
    "        re.search(r'(.)\\1{2,}$', word) or\n",
    "        re.search(r'^(di|ber|ke|se|me|pe|ter|per|mem|men|meng|meny|menge|kan|lah|kah|nya|pun|tah|kah|kah|lah|pun|tah|nya|kan)$', word) or\n",
    "        re.search(r'[aeiou]{3,}', word)):\n",
    "        return 'ms'\n",
    "    return lang\n",
    "\n",
    "# Process reviews in batches\n",
    "for i in tqdm(range(0, len(df), BATCH_SIZE), desc=\"Batch Language Detection\"):\n",
    "    batch_reviews = df.iloc[i:i + BATCH_SIZE]['Normalization'].astype(str).tolist()\n",
    "    batch_reviews = [re.sub(r'[^\\w\\s]', '', review) for review in batch_reviews]\n",
    "    # Split words in each review\n",
    "    batch_splitted = [review.split() for review in batch_reviews]\n",
    "\n",
    "    # Flatten for prediction\n",
    "    flat_words = [word for sublist in batch_splitted for word in sublist]\n",
    "    \n",
    "    # Predict all words at once\n",
    "    predictions, _ = model.predict(flat_words)\n",
    "    predicted_languages = [pred[0].replace('__label__', '') for pred in predictions]\n",
    "\n",
    "\n",
    "\n",
    "    # Reconstruct predictions per review\n",
    "    idx = 0\n",
    "    for splitted in batch_splitted:\n",
    "        word_count = len(splitted)\n",
    "        lang_batch = predicted_languages[idx:idx + word_count]\n",
    "        idx += word_count\n",
    "\n",
    "        classified_languages = [classify_word(word, lang) for word, lang in zip(splitted, lang_batch)]\n",
    "        result = list(zip(splitted, classified_languages))\n",
    "        detect_language_sentences.append(result)\n",
    "\n",
    "        language_counts = Counter(classified_languages)\n",
    "        language_counts.setdefault('en', 0)\n",
    "        language_counts.setdefault('ms', 0)\n",
    "        count_language_sentences.append(language_counts)\n",
    "\n",
    "        count_en, count_ms = language_counts['en'], language_counts['ms']     \n",
    "        if count_en == 0 and count_ms == 0:\n",
    "            label = 'mix'\n",
    "        else:\n",
    "            percentage_difference = abs(count_en - count_ms) / max(count_en, count_ms) * 100 if max(count_en, count_ms) != 0 else 0\n",
    "            label = 'mix' if percentage_difference <= 50 else ('en' if count_en > count_ms else 'ms')\n",
    "        language_labels.append(label)\n",
    "\n",
    "# Add results to DataFrame\n",
    "df['Exp_Language_Detection[Proposed1]'] = language_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b3d1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ File saved to 'SubjectAppsDataset_exp03.xlsx' in sheet 'proposed'.\n"
     ]
    }
   ],
   "source": [
    "# --- Save to Excel ---\n",
    "def save_to_excel(df, path, sheet_name):\n",
    "    with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "sheet_name = \"proposed\"\n",
    "save_to_excel(df, file_name, sheet_name)\n",
    "# --- Final Status ---\n",
    "print(f\"\\n✅ File saved to '{file_name}' in sheet '{sheet_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32428130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
